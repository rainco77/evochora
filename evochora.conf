pipeline {
  # Automatically start services in startupSequence when ServiceManager initializes
  # Set to false for manual control via API (useful for development/testing)
  autoStart = true  # default: true

  startupSequence = ["metadata-indexer", "metadata-persistence-service", "persistence-service-1", "persistence-service-2", "persistence-service-3", "simulation-engine"]

  resources {
    metadata-database {
      className = "org.evochora.datapipeline.resources.database.H2Database"
      options {
        # Option 1: Provide full JDBC URL (takes precedence over dataDirectory)
        # If set, dataDirectory is ignored
        # Example: "jdbc:h2:/path/to/db/evochora;MODE=PostgreSQL"
        #jdbcUrl = "jdbc:h2:${user.home}/evochora/data/evochora;MODE=PostgreSQL"

        # Option 2: Provide data directory (used if jdbcUrl is not set)
        # H2 database file will be created at: <dataDirectory>/evochora
        # Supports variable expansion: ${user.home}, ${java.io.tmpdir}, ${HOME}, etc.
        dataDirectory = "${user.home}/evochora/data"

        # Maximum number of database connections in the pool (default: 10)
        # Increase for high-concurrency scenarios with multiple indexers
        maxPoolSize = 10

        # Minimum number of idle connections maintained in the pool (default: 2)
        # Keeping idle connections reduces latency for new queries
        minIdle = 2

        # Time window in seconds for rate-based metrics calculation (default: 5)
        # Used for disk_writes_per_sec and other sliding window metrics
        # Higher values = smoother metrics, lower values = more responsive
        metricsWindowSeconds = 5
      }
    }
    #test-queue {
    #  className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
    #  options {
    #    capacity = 1000
    #    metricsWindowSeconds = 5
    #  }
    #}

    #consumer-dlq {
    #  className = "org.evochora.datapipeline.resources.queues.InMemoryDeadLetterQueue"
    #  options {
    #    capacity = 100
    #    primaryQueueName = "test-queue"
    #  }
    #}

    #consumer-idempotency-tracker {
    #  className = "org.evochora.datapipeline.resources.idempotency.InMemoryIdempotencyTracker"
    #  options {
    #    ttlSeconds = 60
    #    cleanupThresholdMessages = 10000
    #    cleanupIntervalSeconds = 60
    #  }
    #}

    tick-storage {
      className = "org.evochora.datapipeline.resources.storage.FileSystemStorageResource"
      options {
        # Required: Absolute path to root directory for storing batch files
        # Subdirectories are created automatically based on simulationRunId
        # Example structure: /path/to/storage/sim-123/batch_0000000000000000000_0000000000000000999.pb
        #
        # Supports variable expansion using ${VAR} syntax:
        #   - System properties: ${user.home}, ${java.io.tmpdir}
        #   - Environment variables: ${HOME}, ${USERPROFILE}, ${PROJECT_ROOT}
        #   - Multiple variables: ${user.home}/${PROJECT_NAME}/data
        #
        # Cross-platform examples:
        #   ${user.home}/evochora-data       # Recommended (works everywhere)
        #   ${java.io.tmpdir}/evochora       # Temp directory
        #   ${HOME}/evochora-data            # Linux/macOS
        #   ${USERPROFILE}\\evochora-data    # Windows
        rootDirectory = "${user.home}/evochora/storage"

        # Hierarchical folder organization for batch files
        # Organizes batches into folders based on tick ranges to prevent filesystem
        # bottlenecks from too many files in a single directory.
        #
        # Structure with [100000000, 100000]:
        #   simulationId/001/234/batch_0012340000_0012340999.pb.zst
        #                │   │    └─ Batch file (firstTick to lastTick)
        #                │   └─ Level 1: hundred-thousands within hundred-million
        #                └─ Level 0: hundred-millions (tick / 100,000,000)
        #
        # Examples:
        #   - Tick 12,345,678 → folder 000/123/
        #   - Tick 123,456,789 → folder 001/234/
        #   - Tick 5,000,000,000 → folder 050/000/
        #
        # File discovery: Indexers use paginated listBatchFiles() to discover files
        # efficiently without loading all filenames into memory (S3-compatible).
        # With 1000-tick batches: ~100 files/folder (ideal for S3 pagination).
        folderStructure {
          # Tick range divisors for each folder level (outermost to innermost)
          # Default [100000000, 100000] creates 3-digit folders at both levels
          # Supports up to 99.9 billion ticks (999 × 100M)
          # Each folder contains ~100-1000 batch files depending on batch size
          levels = [100000000, 100000]
        }

        # Compression configuration for storage
        # Compression dramatically reduces disk space and I/O at minimal CPU cost.
        # Measured performance: 145-155x compression ratio, ~5% CPU overhead.
        #
        # Three configuration scenarios:
        #   1. enabled = true: Compression active (CURRENT)
        #   2. enabled = false: Explicitly disabled, no compression
        #   3. Missing section: No compression, backward compatible
        #
        # For a 1000x1000 simulation with 100 organisms:
        #   - Uncompressed: ~3.6 MB per tick → 3.6 GB per 1000 ticks
        #   - Compressed:   ~25 KB per tick → 25 MB per 1000 ticks (145x reduction)
        compression {
          enabled = true
          codec = "zstd"  # Recommended: excellent ratio + speed balance
          level = 3       # Optional, default: 3
                          # Range: 1-22
                          # Level 1: Fastest (400-500 MB/s), ~80x ratio
                          # Level 3: Balanced (400-500 MB/s), ~145x ratio (default)
                          # Level 9: Better ratio (200-300 MB/s), ~160x ratio
                          # Level 19-22: Max ratio (very slow), diminishing returns
        }
        #
        # Notes:
        #   - Compressed files use .zst extension (e.g., batch_000_999.pb.zst)
        #   - Backward compatible: Can read old uncompressed .pb files
        #   - Decompression is automatic and transparent
        #
        # Cross-platform support:
        #   - Windows x64: ✓ Works (bundled native library)
        #   - Linux x64/ARM64: ✓ Works (bundled native library)
        #   - macOS x64/ARM64: ✓ Works (bundled native library)
        #   - Docker (glibc): ✓ Works with ubuntu, debian, amazonlinux, etc.
        #   - Docker (musl/Alpine): ⚠ Requires additional setup (see below)
        #
        # Alpine Linux Docker Setup:
        #   Alpine uses musl libc instead of glibc. Two options:
        #
        #   Option A: Install glibc compatibility layer (recommended)
        #     FROM alpine:latest
        #     RUN apk add --no-cache gcompat
        #     # zstd-jni will use bundled library with gcompat
        #
        #   Option B: Install native zstd package
        #     FROM alpine:latest
        #     RUN apk add --no-cache zstd-jni zstd-libs
        #     # Uses Alpine's native zstd implementation
        #
        #   Option C: Use glibc-based base image (easiest)
        #     FROM ubuntu:22.04
        #     # or FROM debian:bookworm
        #     # or FROM amazoncorretto:21-alpine3.19 (includes gcompat)
        #     # Works immediately without additional packages
      }
    }

    persistence-dlq {
      className = "org.evochora.datapipeline.resources.queues.InMemoryDeadLetterQueue"
      options {
        # Maximum number of failed batches the DLQ can hold (default: 100)
        capacity = 100

        # Logical name of the primary queue being protected (for logging/monitoring)
        primaryQueueName = "raw-tick-data"
      }
    }

    persistence-idempotency-tracker {
      className = "org.evochora.datapipeline.resources.idempotency.InMemoryIdempotencyTracker"
      options {
        # Time-to-live for idempotency keys in seconds (default: 3600)
        # After TTL expires, keys are eligible for cleanup
        ttlSeconds = 3600

        # Number of messages before triggering cleanup (default: 10000)
        cleanupThresholdMessages = 10000

        # Interval between cleanup cycles in seconds (default: 60)
        cleanupIntervalSeconds = 60
      }
    }

    #raw-tick-data-null {
    #  # TEST: Using NullQueue (/dev/null) to measure pure simulation performance
    #  className = "org.evochora.datapipeline.resources.queues.NullQueue"
    #  options {
    #  }
    #
    #  # Original configuration (for comparison):
    #  # className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
    #  # options {
    #  #   capacity = 10000
    #  # }
    #}

    raw-tick-data {
      className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
      options {
        capacity = 10000
        # TEST: Disable all timestamp tracking inside the queue
        #disableTimestamps = true

        # Coalescing delay for competing consumers (milliseconds)
        # When queue is empty and producer is slow, wait this long after receiving
        # first tick to accumulate more ticks, improving batch sizes.
        # The drainLock GUARANTEES non-overlapping consecutive batch ranges.
        # Recommended: 100-200ms for slow producers with competing consumers
        coalescingDelayMs = 500
      }
    }

    context-data {
      className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
      options {
        capacity = 10
      }
    }

    #consumer-dlq {
    #  className = "org.evochora.datapipeline.resources.queues.InMemoryDeadLetterQueue"
    #  options {
    #    capacity = 100
    #    primaryQueueName = "raw-tick-data"
    #  }
    #}

    #consumer-idempotency-tracker {
    #  className = "org.evochora.datapipeline.resources.idempotency.InMemoryIdempotencyTracker"
    #  options {
    #    ttlSeconds = 3600
    #    cleanupThresholdMessages = 100
    #    cleanupIntervalSeconds = 60
    #  }
    #}
  }

  services {
    metadata-persistence-service {
      className = "org.evochora.datapipeline.services.MetadataPersistenceService"
      resources {
        # Required: Input queue for SimulationMetadata messages
        input = "queue-in:context-data"

        # Required: Storage backend for writing metadata
        # Uses same storage as tick data to keep metadata and ticks together
        storage = "storage-write:tick-storage"

        # Optional: Dead letter queue for failed metadata (shared with PersistenceService)
        dlq = "queue-out:persistence-dlq"
      }
      options {
        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000
      }
    }

    metadata-indexer {
      className = "org.evochora.datapipeline.services.indexers.MetadataIndexer"
      resources {
        # Required: Storage backend for reading metadata files
        # Must be the same storage where MetadataPersistenceService writes
        storage = "storage-read:tick-storage"

        # Required: Database for writing indexed metadata
        # Uses H2Database with connection pooling via HikariCP
        # Format: "usageType:resourceName" where usageType is "database-metadata"
        database = "database-metadata:metadata-database"
      }
      options {
        # Polling interval in milliseconds when waiting for metadata file to appear (default: 1000)
        # Lower values = faster detection of new files, higher CPU usage
        # Higher values = lower CPU usage, slower detection
        metadataFilePollIntervalMs = 1000

        # Maximum time in milliseconds to wait for metadata file before timeout (default: 60000)
        # MetadataPersistenceService writes metadata.pb immediately at simulation start
        # If file doesn't appear within this timeout, an error is recorded
        # Recommended: 60000ms (1 minute) for network storage, 30000ms for local disk
        metadataFileMaxPollDurationMs = 60000

        # Optional: Specify a specific simulation run ID to index
        # If set, the indexer will only process this single run ID instead of discovering
        # and indexing all available runs from storage. Useful for:
        #   - Re-indexing a specific run after database corruption
        #   - Testing/debugging indexing of a particular simulation
        #   - Selective indexing in scenarios with many runs
        # If not set (or commented out), the indexer discovers and processes all runs
        # Format: YYYYMMDD-HHmmssSS-<UUID> (e.g., 20251009-14302512-550e8400-e29b-41d4-a716-446655440000)
        #runId = "20251009-14302512-550e8400-e29b-41d4-a716-446655440000"
      }
    }

    simulation-engine {
      className = "org.evochora.datapipeline.services.SimulationEngine"
      resources {
        tickData = "queue-out:raw-tick-data"
        metadataOutput = "queue-out:context-data"
      }
      options {
        # Sampling interval: capture tick data every N ticks (1 = every tick)
        samplingInterval = 1

        # Time window in seconds for ticks_per_second calculation (default: 1)
        metricsWindowSeconds = 5

        # Optional: Pause simulation at specific ticks for debugging
        pauseTicks = []

        # Random seed for reproducible simulations (omit for random seed)
        seed = 42

        # Environment configuration
        environment {
          # World dimensions (2D: [width, height], 3D: [width, height, depth])
          shape = [100, 100]

          # Topology: "TORUS" for wraparound edges, anything else for bounded
          topology = "TORUS"
        }

        # Energy distribution strategies (multiple can be active simultaneously)
        energyStrategies = [
          {
            className = "org.evochora.runtime.worldgen.GeyserCreator"
            options {
              # Number of geysers to spawn
              count = 5

              # Tick interval between eruptions
              interval = 100

              # Energy amount placed per eruption
              amount = 1000

              # Radius around placement that must be unowned by organisms
              safetyRadius = 2
            }
          },
        #  {
        #    className = "org.evochora.runtime.worldgen.SolarRadiationCreator"
        #    options {
        #      # Probability per execution to spawn energy (0.0 to 1.0)
        #      probability = 0.1
        #
        #      # Energy amount placed when spawn succeeds
        #      amount = 500
        #
        #      # Radius around placement that must be unowned by organisms
        #      safetyRadius = 1
        #
        #      # Number of independent spawn attempts per tick
        #      executionsPerTick = 3
        #    }
        #  }
        ]

        # Initial organisms to spawn at simulation start
        organisms = [
          {
            # Path to Evochora assembly program file
            program = "assembly/primordial/main.s"

            # Initial energy level
            initialEnergy = 10000

            # Placement in the environment
            placement {
              # Position coordinates [x, y] for 2D or [x, y, z] for 3D
              positions = [5, 5]
            }
          }
        ]

        # Optional: User-defined metadata for experiment tracking
        metadata {
          experiment = "test-run"
          version = "1.0"
        }
      }
    }

    #tick-consumer {
    #  className = "org.evochora.datapipeline.services.DummyConsumerService"
    #  resources {
    #    input = "queue-in:raw-tick-data"
    #    idempotencyTracker = "consumer-idempotency-tracker"
    #    dlq = "queue-out:consumer-dlq"
    #  }
    #  options {
    #    #processingDelayMs = 50
    #    maxMessages = -1
    #  }
    #}

    persistence-service-1 {
      className = "org.evochora.datapipeline.services.PersistenceService"
      resources {
        # Required: Input queue for TickData messages
        input = "queue-in:raw-tick-data"

        # Required: Storage backend for writing batches
        storage = "storage-write:tick-storage"

        # Optional: Dead letter queue for failed batches
        dlq = "queue-out:persistence-dlq"

        # Optional: Idempotency tracker to detect duplicate ticks (bug detection)
        idempotencyTracker = "persistence-idempotency-tracker"
      }
      options {
        # Maximum number of TickData messages to batch together (default: 1000)
        maxBatchSize = 1000

        # Maximum seconds to wait before flushing partial batch (default: 5)
        batchTimeoutSeconds = 5

        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000

        # Maximum seconds to wait for shutdown batch completion (default: 15)
        # When shutdown is requested, the service attempts to complete the current batch
        # within this timeout to avoid leaving .tmp files. Critical for spot instances
        # which have ~2min total shutdown window. Recommended values:
        #   - Spot instances: 15s (default) - leaves time for other services
        #   - On-premise: 60s - maximizes data integrity
        # If timeout exceeded, batch may be lost but .tmp file remains as evidence
        shutdownBatchTimeoutSeconds = 15
      }
    }

    persistence-service-2 {
      className = "org.evochora.datapipeline.services.PersistenceService"
      resources {
        # Required: Input queue for TickData messages
        input = "queue-in:raw-tick-data"

        # Required: Storage backend for writing batches
        storage = "storage-write:tick-storage"

        # Optional: Dead letter queue for failed batches
        dlq = "queue-out:persistence-dlq"

        # Optional: Idempotency tracker to detect duplicate ticks (bug detection)
        idempotencyTracker = "persistence-idempotency-tracker"
      }
      options {
        # Maximum number of TickData messages to batch together (default: 1000)
        maxBatchSize = 1000

        # Maximum seconds to wait before flushing partial batch (default: 5)
        batchTimeoutSeconds = 5

        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000

        # Maximum seconds to wait for shutdown batch completion (default: 15)
        # When shutdown is requested, the service attempts to complete the current batch
        # within this timeout to avoid leaving .tmp files. Critical for spot instances
        # which have ~2min total shutdown window. Recommended values:
        #   - Spot instances: 15s (default) - leaves time for other services
        #   - On-premise: 60s - maximizes data integrity
        # If timeout exceeded, batch may be lost but .tmp file remains as evidence
        shutdownBatchTimeoutSeconds = 15
      }
    }

    persistence-service-3 {
      className = "org.evochora.datapipeline.services.PersistenceService"
      resources {
        # Required: Input queue for TickData messages
        input = "queue-in:raw-tick-data"

        # Required: Storage backend for writing batches
        storage = "storage-write:tick-storage"

        # Optional: Dead letter queue for failed batches
        dlq = "queue-out:persistence-dlq"

        # Optional: Idempotency tracker to detect duplicate ticks (bug detection)
        idempotencyTracker = "persistence-idempotency-tracker"
      }
      options {
        # Maximum number of TickData messages to batch together (default: 1000)
        maxBatchSize = 1000

        # Maximum seconds to wait before flushing partial batch (default: 5)
        batchTimeoutSeconds = 5

        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000

        # Maximum seconds to wait for shutdown batch completion (default: 15)
        # When shutdown is requested, the service attempts to complete the current batch
        # within this timeout to avoid leaving .tmp files. Critical for spot instances
        # which have ~2min total shutdown window. Recommended values:
        #   - Spot instances: 15s (default) - leaves time for other services
        #   - On-premise: 60s - maximizes data integrity
        # If timeout exceeded, batch may be lost but .tmp file remains as evidence
        shutdownBatchTimeoutSeconds = 15
      }
    }

    #dummy-consumer {
    #  className = "org.evochora.datapipeline.services.DummyConsumerService"
    #  resources {
    #    input = "queue-in:test-queue"
    #    idempotencyTracker = "consumer-idempotency-tracker"
    #    dlq = "queue-out:consumer-dlq"
    #  }
    #  options {
    #    # Artificial delay per message in milliseconds (default: 0)
    #    processingDelayMs = 50
    #
    #    # Maximum messages to process, -1 for unlimited (default: -1)
    #    maxMessages = 100
    #
    #    # Time window in seconds for throughput calculation (default: 5)
    #    metricsWindowSeconds = 5
    #
    #    # Maximum processing attempts before sending to DLQ (default: 3)
    #    maxRetries = 3
    #
    #    # Whether to log received messages at DEBUG level (default: false)
    #    #logReceivedMessages = false
    #  }
    #}

    #dummy-producer {
    #  className = "org.evochora.datapipeline.services.DummyProducerService"
    #  resources {
    #    output = "queue-out:test-queue?metricsWindowSeconds=2"
    #  }
    #  options {
    #    # Milliseconds between messages (default: 1000)
    #    intervalMs = 100
    #
    #    # Maximum messages to send, -1 for unlimited (default: -1)
    #    maxMessages = 100
    #
    #    # Time window in seconds for throughput calculation (default: 5)
    #    metricsWindowSeconds = 5
    #
    #    # Prefix for the message content (default: "Message")
    #    #messagePrefix = "Message"
    #  }
    #}
  }
}

logging {
  format = "PLAIN"  # Can be "PLAIN" or "JSON". Defaults to JSON
  default-level = "INFO"  # Default log level for all loggers
  levels {
    # Specific logger levels - override the default for particular components
    "org.evochora.datapipeline.ServiceManager" = "INFO"
  }
}

# The node block configures the server process itself
node {
  # Show ASCII art welcome message on startup (default: false)
  show-welcome-message = true

  # Defines all long-running processes the Node should start and manage
  processes {

    # Pipeline process - manages data pipeline services (simulation, persistence, etc.)
    # Must be defined BEFORE http process since http depends on it
    pipeline {
      className = "org.evochora.datapipeline.ServiceManagerProcess"
      options = ${pipeline}  # References the top-level pipeline configuration
    }

    # Logical name for the HTTP server process
    http {
      className = "org.evochora.node.processes.http.HttpServerProcess"

      # Declare dependency on pipeline process
      require = {
        serviceManager = "pipeline"
      }

      options {
        network {
          host = "0.0.0.0"
          port = 8080

          # Optional: Configure the Jetty thread pool for HTTP request handling
          # Threads are named "<processName>-http-<number>" for easier monitoring
          threadPool {
            minThreads = 8         # Minimum number of threads (default: 8)
            maxThreads = 200       # Maximum number of threads (default: 200)
            idleTimeoutMs = 60000  # Idle timeout in milliseconds (default: 60000)
          }
        }

        # All routes are defined within the HttpServerProcess's options
        routes {
          # The nesting of objects defines the URL paths.
          # Actions ($controller, $static) are defined by keys prefixed with '$'.
          pipeline {
            # ACTION: Serves static UI files at the base path "/pipeline"
            # The static file handler serves from the classpath. A directory named
            # 'web/pipeline-control' should exist in 'src/main/resources'.
            #"$static" = "/web/pipeline-control"

            # Builds the sub-path "/pipeline/api"
            api {
              # ACTION: Serves a controller at "/pipeline/api"
              "$controller" {
                className = "org.evochora.node.processes.http.api.pipeline.PipelineController"
                options {}
              }
            }
          }
        }
      }
    }
  }
}