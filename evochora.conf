

pipeline {
  # Automatically start services in startupSequence when ServiceManager initializes
  # Set to false for manual control via API (useful for development/testing)
  autoStart = true  # default: true

  startupSequence = ["dummy-indexer", "metadata-indexer", "metadata-persistence-service", "persistence-service-1", "persistence-service-2", "persistence-service-3", "simulation-engine"]
  
  # Shared database configuration for all H2-based resources
  # Can be referenced by ${pipeline.database} in resource options with selective overrides
  database {
    # JDBC URL for H2 database connection
    # Both H2TopicResource and H2Database use this for consistency
    # 
    # Format: jdbc:h2:<path_to_database_file>[;<parameters>]
    # The path should include the database filename (without .mv.db extension)
    # H2 will create <path>.mv.db and <path>.trace.db files
    # 
    # Important H2 Parameters:
    #   - MODE=PostgreSQL: Use PostgreSQL-compatible SQL (required for BYTEA, MERGE, etc.)
    #   - AUTO_SERVER=TRUE: Allow multiple processes (enables H2 Console alongside application)
    # 
    # Variable expansion is handled by PathExpansion.java:
    #   - ${user.home} → /home/username
    #   - ${java.io.tmpdir} → /tmp
    #   - ${HOME} → environment variable
    jdbcUrl = "jdbc:h2:${user.home}/evochora/data/evochora;MODE=PostgreSQL;DB_CLOSE_ON_EXIT=FALSE"
    # Note: AUTO_SERVER=TRUE is not compatible with DB_CLOSE_ON_EXIT=FALSE
    # For external DB client access while app is running, use H2 TCP Server (TODO: implement H2TcpServerProcess)

    # Database credentials (default: username=sa, password=empty)
    # Used by all H2-based resources (topics, index database, etc.)
    username = "sa"
    password = ""

    # Default connection pool settings (can be overridden per resource)
    maxPoolSize = 10  # Maximum number of database connections in the pool
    minIdle = 2       # Minimum number of idle connections maintained in the pool

    # Default metrics window (can be overridden per resource)
    metricsWindowSeconds = 60  # Time window for rate-based metrics calculation
  }

  resources {
    # JVM Memory Monitoring - exposes heap, thread, and runtime metrics
    # Provides live JVM statistics for monitoring and alerting
    # No configuration needed - all metrics are queried live from Runtime/ManagementFactory
    jvm-memory {
      className = "org.evochora.datapipeline.resources.monitoring.JvmMemoryMonitor"
      options { }
    }

    # H2-based topic for pub/sub messaging between pipeline services
    # Provides persistent, multi-writer queuing with consumer groups and competing consumers
    batch-topic {
      className = "org.evochora.datapipeline.resources.topics.H2TopicResource"
      options = ${pipeline.database} {
        # Topic-specific options (not in shared database config)
        claimTimeout = 300  # Stuck message reassignment timeout in seconds (default: 300)
        
        # All other options (jdbcUrl, username, password, maxPoolSize, minIdle, metricsWindowSeconds)
        # are inherited from ${pipeline.database} without modification
      }
    }

    # H2-based topic for metadata notifications (MetadataPersistenceService → MetadataIndexer)
    # Enables event-driven metadata indexing without storage polling
    metadata-topic {
      className = "org.evochora.datapipeline.resources.topics.H2TopicResource"
      options = ${pipeline.database} {
        # Stuck message reassignment timeout in seconds (default: 300)
        # For metadata-topic: single consumer group, so timeouts are unlikely
        # Set to same value as batch-topic for consistency
        claimTimeout = 300
        
        # All other options (jdbcUrl, username, password, maxPoolSize, minIdle, metricsWindowSeconds)
        # are inherited from ${pipeline.database} without modification
      }
    }

    index-database {
      className = "org.evochora.datapipeline.resources.database.H2Database"
      options = ${pipeline.database}
      # All options inherited 1:1 from ${pipeline.database} without modification
    }
    #test-queue {
    #  className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
    #  options {
    #    capacity = 1000
    #    metricsWindowSeconds = 5
    #  }
    #}

    #consumer-dlq {
    #  className = "org.evochora.datapipeline.resources.queues.InMemoryDeadLetterQueue"
    #  options {
    #    capacity = 100
    #    primaryQueueName = "test-queue"
    #  }
    #}

    #consumer-idempotency-tracker {
    #  className = "org.evochora.datapipeline.resources.idempotency.InMemoryIdempotencyTracker"
    #  options {
    #    ttlSeconds = 60
    #    cleanupThresholdMessages = 10000
    #    cleanupIntervalSeconds = 60
    #  }
    #}

    tick-storage {
      className = "org.evochora.datapipeline.resources.storage.FileSystemStorageResource"
      options {
        # Required: Absolute path to root directory for storing batch files
        # Subdirectories are created automatically based on simulationRunId
        # Example structure: /path/to/storage/sim-123/batch_0000000000000000000_0000000000000000999.pb
        #
        # Supports variable expansion using ${VAR} syntax:
        #   - System properties: ${user.home}, ${java.io.tmpdir}
        #   - Environment variables: ${HOME}, ${USERPROFILE}, ${PROJECT_ROOT}
        #   - Multiple variables: ${user.home}/${PROJECT_NAME}/data
        #
        # Cross-platform examples:
        #   ${user.home}/evochora-data       # Recommended (works everywhere)
        #   ${java.io.tmpdir}/evochora       # Temp directory
        #   ${HOME}/evochora-data            # Linux/macOS
        #   ${USERPROFILE}\\evochora-data    # Windows
        rootDirectory = "${user.home}/evochora/raw"

        # Hierarchical folder organization for batch files
        # Organizes batches into folders based on tick ranges to prevent filesystem
        # bottlenecks from too many files in a single directory.
        #
        # Structure with [100000000, 100000]:
        #   simulationId/001/234/batch_0012340000_0012340999.pb.zst
        #                │   │    └─ Batch file (firstTick to lastTick)
        #                │   └─ Level 1: hundred-thousands within hundred-million
        #                └─ Level 0: hundred-millions (tick / 100,000,000)
        #
        # Examples:
        #   - Tick 12,345,678 → folder 000/123/
        #   - Tick 123,456,789 → folder 001/234/
        #   - Tick 5,000,000,000 → folder 050/000/
        #
        # File discovery: Indexers use paginated listBatchFiles() to discover files
        # efficiently without loading all filenames into memory (S3-compatible).
        # With 1000-tick batches: ~100 files/folder (ideal for S3 pagination).
        folderStructure {
          # Tick range divisors for each folder level (outermost to innermost)
          # Default [100000000, 100000] creates 3-digit folders at both levels
          # Supports up to 99.9 billion ticks (999 × 100M)
          # Each folder contains ~100-1000 batch files depending on batch size
          levels = [100000000, 100000]
        }

        # Compression configuration for storage
        # Compression dramatically reduces disk space and I/O at minimal CPU cost.
        # Measured performance: 145-155x compression ratio, ~5% CPU overhead.
        #
        # Three configuration scenarios:
        #   1. enabled = true: Compression active (CURRENT)
        #   2. enabled = false: Explicitly disabled, no compression
        #   3. Missing section: No compression, backward compatible
        #
        # For a 1000x1000 simulation with 100 organisms:
        #   - Uncompressed: ~3.6 MB per tick → 3.6 GB per 1000 ticks
        #   - Compressed:   ~25 KB per tick → 25 MB per 1000 ticks (145x reduction)
        compression {
          enabled = true
          codec = "zstd"  # Recommended: excellent ratio + speed balance
          level = 3       # Optional, default: 3
                          # Range: 1-22
                          # Level 1: Fastest (400-500 MB/s), ~80x ratio
                          # Level 3: Balanced (400-500 MB/s), ~145x ratio (default)
                          # Level 9: Better ratio (200-300 MB/s), ~160x ratio
                          # Level 19-22: Max ratio (very slow), diminishing returns
        }
        #
        # Notes:
        #   - Compressed files use .zst extension (e.g., batch_000_999.pb.zst)
        #   - Backward compatible: Can read old uncompressed .pb files
        #   - Decompression is automatic and transparent
        #
        # Cross-platform support:
        #   - Windows x64: ✓ Works (bundled native library)
        #   - Linux x64/ARM64: ✓ Works (bundled native library)
        #   - macOS x64/ARM64: ✓ Works (bundled native library)
        #   - Docker (glibc): ✓ Works with ubuntu, debian, amazonlinux, etc.
        #   - Docker (musl/Alpine): ⚠ Requires additional setup (see below)
        #
        # Alpine Linux Docker Setup:
        #   Alpine uses musl libc instead of glibc. Two options:
        #
        #   Option A: Install glibc compatibility layer (recommended)
        #     FROM alpine:latest
        #     RUN apk add --no-cache gcompat
        #     # zstd-jni will use bundled library with gcompat
        #
        #   Option B: Install native zstd package
        #     FROM alpine:latest
        #     RUN apk add --no-cache zstd-jni zstd-libs
        #     # Uses Alpine's native zstd implementation
        #
        #   Option C: Use glibc-based base image (easiest)
        #     FROM ubuntu:22.04
        #     # or FROM debian:bookworm
        #     # or FROM amazoncorretto:21-alpine3.19 (includes gcompat)
        #     # Works immediately without additional packages
      }
    }

    persistence-dlq {
      className = "org.evochora.datapipeline.resources.queues.InMemoryDeadLetterQueue"
      options {
        # Maximum number of failed batches the DLQ can hold (default: 100)
        capacity = 100

        # Logical name of the primary queue being protected (for logging/monitoring)
        primaryQueueName = "raw-tick-data"
      }
    }

    persistence-idempotency-tracker {
      className = "org.evochora.datapipeline.resources.idempotency.InMemoryIdempotencyTracker"
      options {
        # Maximum number of keys to track (hard limit, FIFO eviction)
        # At 100k TPS: 10M keys = 100 second window
        # At 163k TPS: 10M keys = 61 second window
        # Memory: 10M keys ≈ 1.3 GB RAM (guaranteed, no growth!)
        maxKeys = 10000000

        # Initial HashMap capacity (default: maxKeys)
        # Set to maxKeys to avoid rehashing during warmup
        initialCapacity = 10000000
      }
    }

    #raw-tick-data-null {
    #  # TEST: Using NullQueue (/dev/null) to measure pure simulation performance
    #  className = "org.evochora.datapipeline.resources.queues.NullQueue"
    #  options {
    #  }
    #
    #  # Original configuration (for comparison):
    #  # className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
    #  # options {
    #  #   capacity = 10000
    #  # }
    #}

    raw-tick-data {
      className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
      options {
        capacity = 10000
        # TEST: Disable all timestamp tracking inside the queue
        #disableTimestamps = true

        # Coalescing delay for competing consumers (milliseconds)
        # When queue is empty and producer is slow, wait this long after receiving
        # first tick to accumulate more ticks, improving batch sizes.
        # The drainLock GUARANTEES non-overlapping consecutive batch ranges.
        # Recommended: 100-200ms for slow producers with competing consumers
        coalescingDelayMs = 500
      }
    }

    context-data {
      className = "org.evochora.datapipeline.resources.queues.InMemoryBlockingQueue"
      options {
        capacity = 10
      }
    }

    #consumer-dlq {
    #  className = "org.evochora.datapipeline.resources.queues.InMemoryDeadLetterQueue"
    #  options {
    #    capacity = 100
    #    primaryQueueName = "raw-tick-data"
    #  }
    #}

    #consumer-idempotency-tracker {
    #  className = "org.evochora.datapipeline.resources.idempotency.InMemoryIdempotencyTracker"
    #  options {
    #    ttlSeconds = 3600
    #    cleanupThresholdMessages = 100
    #    cleanupIntervalSeconds = 60
    #  }
    #}
  }

  services {
    metadata-persistence-service {
      className = "org.evochora.datapipeline.services.MetadataPersistenceService"
      resources {
        # Required: Input queue for SimulationMetadata messages
        input = "queue-in:context-data"

        # Required: Storage backend for writing metadata
        # Uses same storage as tick data to keep metadata and ticks together
        storage = "storage-write:tick-storage"

        # Required: Topic for metadata notifications (enables event-driven indexing)
        topic = "topic-write:metadata-topic"

        # Optional: Dead letter queue for failed metadata (shared with PersistenceService)
        dlq = "queue-out:persistence-dlq"
      }
      options {
        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000
      }
    }

    #########################################################
    # Indexer Section                                       #
    #########################################################

    # Optional: Specify a specific simulation run ID for post-mortem mode
    # If set, all indexers will process only this single run ID instead of discovering
    # the latest run from storage. Useful for:
    #   - Re-indexing a specific run after database corruption
    #   - Testing/debugging indexing of a particular simulation
    #   - Post-mortem analysis of completed simulations
    # If not set (or commented out), indexers discover the latest run from storage
    # based on their start time (only runs starting AFTER indexer launch are discovered)
    # Format: YYYYMMDD-HHmmssSS-<UUID> (e.g., 20251009-14302512-550e8400-e29b-41d4-a716-446655440000)
    #runId = "20251009-14302512-550e8400-e29b-41d4-a716-446655440000"


    metadata-indexer {
      className = "org.evochora.datapipeline.services.indexers.MetadataIndexer"
      resources {
        # Required: Storage backend for reading metadata files
        # Must be the same storage where MetadataPersistenceService writes
        storage = "storage-read:tick-storage"

        # Required: Database for writing indexed metadata
        # Uses H2Database with connection pooling via HikariCP
        database = "db-meta-write:index-database"

        # Required: Topic for metadata notifications (event-driven indexing)
        # Subscribes to metadata-topic with dedicated consumer group
        topic = "topic-read:metadata-topic?consumerGroup=metadata"
      }
      options {
        # Maximum time in milliseconds to wait for metadata notification (default: 30000)
        # MetadataPersistenceService publishes notification immediately after storage write
        # If notification doesn't arrive within this timeout, indexer enters ERROR state
        # This timeout should account for MetadataPersistenceService processing time
        # Recommended: 30000ms (30 seconds) for most scenarios
        topicPollTimeoutMs = 30000

        # Inherits from central services.runId (if set)
        # If services.runId not set → automatic discovery from storage
        # Can be overridden here for indexer-specific post-mortem mode
        runId = ${?pipeline.services.runId}
      }
    }

    # DummyIndexer - Test indexer for validating metadata reading infrastructure (Phase 2.5.1)
    # Purpose: Validates that indexers can discover runs, poll for metadata, and read from database
    # Does NOT process tick data - only tests metadata reading capability
    dummy-indexer {
      className = "org.evochora.datapipeline.services.indexers.DummyIndexer"
      
      resources {
        # Required: Storage backend for discovering simulation runs
        # Used by AbstractIndexer for run ID discovery (timestamp-based)
        # Must match storage where SimulationEngine writes metadata.pb
        storage = "storage-read:tick-storage"
        
        # Required: Database for reading indexed metadata
        # Polls database until MetadataIndexer has written metadata
        # Uses read-only wrapper (IMetadataReader) with O(1) metrics
        # Format: "usageType:resourceName" where usageType is "db-meta-read"
        metadata = "db-meta-read:index-database"

        # Required: Topic for metadata notifications (event-driven indexing)
        # Subscribes to metadata-topic with dedicated consumer group
        topic = "topic-read:metadata-topic?consumerGroup=metadata"
      }
      
      options {
        # Polling interval in milliseconds when waiting for metadata in database (default: 1000)
        # DummyIndexer polls database.getMetadata() until MetadataIndexer completes
        # Lower values = faster detection of indexed metadata, higher database load
        # Higher values = lower database load, slower detection
        # Recommended: 1000ms for local databases, 2000-5000ms for network databases
        pollIntervalMs = 1000
        
        # Maximum time in milliseconds to wait for metadata before timeout (default: 300000)
        # If metadata doesn't appear in database within this timeout, indexer enters ERROR state
        # Should be >= metadataFileMaxPollDurationMs + indexing time
        # Recommended: 300000ms (5 minutes) to account for slow MetadataIndexer and retries
        maxPollDurationMs = 300000
        
        # Inherits from central services.runId (if set)
        # If services.runId not set → automatic discovery from storage
        # Can be overridden here for indexer-specific post-mortem mode
        runId = ${?pipeline.services.runId}
      }
    }

    simulation-engine {
      className = "org.evochora.datapipeline.services.SimulationEngine"
      resources {
        tickData = "queue-out:raw-tick-data"
        metadataOutput = "queue-out:context-data"
      }
      options {
        # Sampling interval: capture tick data every N ticks (1 = every tick)
        samplingInterval = 1

        # Time window in seconds for ticks_per_second calculation (default: 1)
        metricsWindowSeconds = 5

        # Optional: Pause simulation at specific ticks for debugging
        pauseTicks = []

        # Random seed for reproducible simulations (omit for random seed)
        seed = 42

        # Environment configuration
        environment {
          # World dimensions (2D: [width, height], 3D: [width, height, depth])
          shape = [100, 100]

          # Topology: "TORUS" for wraparound edges, anything else for bounded
          topology = "TORUS"
        }

        # Energy distribution strategies (multiple can be active simultaneously)
        energyStrategies = [
          {
            className = "org.evochora.runtime.worldgen.GeyserCreator"
            options {
              # Number of geysers to spawn
              count = 5

              # Tick interval between eruptions
              interval = 100

              # Energy amount placed per eruption
              amount = 1000

              # Radius around placement that must be unowned by organisms
              safetyRadius = 2
            }
          },
        #  {
        #    className = "org.evochora.runtime.worldgen.SolarRadiationCreator"
        #    options {
        #      # Probability per execution to spawn energy (0.0 to 1.0)
        #      probability = 0.1
        #
        #      # Energy amount placed when spawn succeeds
        #      amount = 500
        #
        #      # Radius around placement that must be unowned by organisms
        #      safetyRadius = 1
        #
        #      # Number of independent spawn attempts per tick
        #      executionsPerTick = 3
        #    }
        #  }
        ]

        # Initial organisms to spawn at simulation start
        organisms = [
          {
            # Path to Evochora assembly program file
            program = "assembly/primordial/main.s"
            program = "assembly/examples/simple.s"

            # Initial energy level
            initialEnergy = 65000

            # Placement in the environment
            placement {
              # Position coordinates [x, y] for 2D or [x, y, z] for 3D
              positions = [5, 5]
            }
          }
        ]

        # Optional: User-defined metadata for experiment tracking
        metadata {
          experiment = "test-run"
          version = "1.0"
        }
      }
    }

    #tick-consumer {
    #  className = "org.evochora.datapipeline.services.DummyConsumerService"
    #  resources {
    #    input = "queue-in:raw-tick-data"
    #    idempotencyTracker = "consumer-idempotency-tracker"
    #    dlq = "queue-out:consumer-dlq"
    #  }
    #  options {
    #    #processingDelayMs = 50
    #    maxMessages = -1
    #  }
    #}

    persistence-service-1 {
      className = "org.evochora.datapipeline.services.PersistenceService"
      resources {
        # Required: Input queue for TickData messages
        input = "queue-in:raw-tick-data"

        # Required: Storage backend for writing batches
        storage = "storage-write:tick-storage"

        # Required: Topic for batch notifications (enables event-driven indexing)
        topic = "topic-write:batch-topic"

        # Optional: Dead letter queue for failed batches
        dlq = "queue-out:persistence-dlq"

        # Optional: Idempotency tracker to detect duplicate ticks (bug detection)
        idempotencyTracker = "persistence-idempotency-tracker"
      }
      options {
        # Maximum number of TickData messages to batch together (default: 1000)
        maxBatchSize = 1000

        # Maximum seconds to wait before flushing partial batch (default: 5)
        batchTimeoutSeconds = 5

        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000

        # Maximum seconds to wait for shutdown batch completion (default: 15)
        # When shutdown is requested, the service attempts to complete the current batch
        # within this timeout to avoid leaving .tmp files. Critical for spot instances
        # which have ~2min total shutdown window. Recommended values:
        #   - Spot instances: 15s (default) - leaves time for other services
        #   - On-premise: 60s - maximizes data integrity
        # If timeout exceeded, batch may be lost but .tmp file remains as evidence
        shutdownBatchTimeoutSeconds = 15
      }
    }

    persistence-service-2 {
      className = "org.evochora.datapipeline.services.PersistenceService"
      resources {
        # Required: Input queue for TickData messages
        input = "queue-in:raw-tick-data"

        # Required: Storage backend for writing batches
        storage = "storage-write:tick-storage"

        # Required: Topic for batch notifications (enables event-driven indexing)
        topic = "topic-write:batch-topic"

        # Optional: Dead letter queue for failed batches
        dlq = "queue-out:persistence-dlq"

        # Optional: Idempotency tracker to detect duplicate ticks (bug detection)
        idempotencyTracker = "persistence-idempotency-tracker"
      }
      options {
        # Maximum number of TickData messages to batch together (default: 1000)
        maxBatchSize = 1000

        # Maximum seconds to wait before flushing partial batch (default: 5)
        batchTimeoutSeconds = 5

        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000

        # Maximum seconds to wait for shutdown batch completion (default: 15)
        # When shutdown is requested, the service attempts to complete the current batch
        # within this timeout to avoid leaving .tmp files. Critical for spot instances
        # which have ~2min total shutdown window. Recommended values:
        #   - Spot instances: 15s (default) - leaves time for other services
        #   - On-premise: 60s - maximizes data integrity
        # If timeout exceeded, batch may be lost but .tmp file remains as evidence
        shutdownBatchTimeoutSeconds = 15
      }
    }

    persistence-service-3 {
      className = "org.evochora.datapipeline.services.PersistenceService"
      resources {
        # Required: Input queue for TickData messages
        input = "queue-in:raw-tick-data"

        # Required: Storage backend for writing batches
        storage = "storage-write:tick-storage"

        # Required: Topic for batch notifications (enables event-driven indexing)
        topic = "topic-write:batch-topic"

        # Optional: Dead letter queue for failed batches
        dlq = "queue-out:persistence-dlq"

        # Optional: Idempotency tracker to detect duplicate ticks (bug detection)
        idempotencyTracker = "persistence-idempotency-tracker"
      }
      options {
        # Maximum number of TickData messages to batch together (default: 1000)
        maxBatchSize = 1000

        # Maximum seconds to wait before flushing partial batch (default: 5)
        batchTimeoutSeconds = 5

        # Maximum retry attempts for transient write failures (default: 3)
        maxRetries = 3

        # Base delay in milliseconds for exponential backoff retry logic (default: 1000)
        # Retry delays follow pattern: base, base*2, base*4, ... (capped at 60000ms)
        retryBackoffMs = 1000

        # Maximum seconds to wait for shutdown batch completion (default: 15)
        # When shutdown is requested, the service attempts to complete the current batch
        # within this timeout to avoid leaving .tmp files. Critical for spot instances
        # which have ~2min total shutdown window. Recommended values:
        #   - Spot instances: 15s (default) - leaves time for other services
        #   - On-premise: 60s - maximizes data integrity
        # If timeout exceeded, batch may be lost but .tmp file remains as evidence
        shutdownBatchTimeoutSeconds = 15
      }
    }

    #dummy-consumer {
    #  className = "org.evochora.datapipeline.services.DummyConsumerService"
    #  resources {
    #    input = "queue-in:test-queue"
    #    idempotencyTracker = "consumer-idempotency-tracker"
    #    dlq = "queue-out:consumer-dlq"
    #  }
    #  options {
    #    # Artificial delay per message in milliseconds (default: 0)
    #    processingDelayMs = 50
    #
    #    # Maximum messages to process before stopping, -1 for unlimited (default: -1)
    #    # Purpose: Limits total messages consumed for testing/demos
    #    # - For tests: Set to specific count (e.g., 100) → service stops after N messages
    #    # - For unlimited: Set to -1 (default) → service runs until manually stopped
    #    # - Memory safety: Prevents unbounded internal state growth in test services
    #    maxMessages = 100
    #
    #    # Time window in seconds for throughput calculation (default: 5)
    #    metricsWindowSeconds = 5
    #
    #    # Maximum processing attempts before sending to DLQ (default: 3)
    #    maxRetries = 3
    #
    #    # Whether to log received messages at DEBUG level (default: false)
    #    #logReceivedMessages = false
    #  }
    #}

    #dummy-producer {
    #  className = "org.evochora.datapipeline.services.DummyProducerService"
    #  resources {
    #    output = "queue-out:test-queue?metricsWindowSeconds=2"
    #  }
    #  options {
    #    # Milliseconds between messages (default: 1000)
    #    intervalMs = 100
    #
    #    # Maximum messages to send before stopping, -1 for unlimited (default: -1)
    #    # Purpose: Limits total messages produced for testing/demos
    #    # - For tests: Set to specific count (e.g., 100) → service stops after N messages
    #    # - For unlimited: Set to -1 (default) → service runs until manually stopped
    #    # - Memory safety: Prevents unbounded internal state growth in test services
    #    maxMessages = 100
    #
    #    # Time window in seconds for throughput calculation (default: 5)
    #    metricsWindowSeconds = 5
    #
    #    # Prefix for the message content (default: "Message")
    #    #messagePrefix = "Message"
    #  }
    #}

    #dummy-writer {
    #  className = "org.evochora.datapipeline.services.DummyWriterService"
    #  resources {
    #    storage = "storage-write:tick-storage"
    #  }
    #  options {
    #    # Milliseconds between write operations (default: 1000)
    #    intervalMs = 1000
    #
    #    # Number of messages per write batch (default: 10)
    #    messagesPerWrite = 10
    #
    #    # Maximum write operations before stopping, -1 for unlimited (default: -1)
    #    # Purpose: Limits total batches written for testing/demos
    #    # - For tests: Set to specific count (e.g., 100) → service stops after N writes
    #    # - For unlimited: Set to -1 (default) → service runs until manually stopped
    #    # - Memory safety: Prevents unbounded internal state growth in test services
    #    maxWrites = -1
    #
    #    # Key prefix for storage (default: "test")
    #    keyPrefix = "test"
    #  }
    #}

    #dummy-reader {
    #  className = "org.evochora.datapipeline.services.DummyReaderService"
    #  resources {
    #    storage = "storage-read:tick-storage"
    #  }
    #  options {
    #    # Milliseconds between polling cycles (default: 1000)
    #    intervalMs = 1000
    #
    #    # Key prefix for filtering files (default: "test")
    #    keyPrefix = "test"
    #
    #    # Enable data validation (default: true)
    #    validateData = true
    #
    #    # Maximum files to process before stopping, -1 for unlimited (default: -1)
    #    # Purpose: Limits total files processed for testing/demos
    #    # - For tests: Set to specific count (e.g., 100) → service stops after N files
    #    # - For unlimited: Set to -1 (default) → service runs until manually stopped
    #    # - Memory safety: Prevents unbounded processedFiles Set growth (CRITICAL!)
    #    #   Without this limit, processedFiles grows unbounded → memory leak
    #    maxFiles = -1
    #  }
    #}
  }
}

# The node block configures the server process itself
node {
  # Show ASCII art welcome message on startup (default: false)
  show-welcome-message = true

  # Defines all long-running processes the Node should start and manage
  processes {

    # Pipeline process - manages data pipeline services (simulation, persistence, etc.)
    # Must be defined BEFORE http process since http depends on it
    pipeline {
      className = "org.evochora.datapipeline.ServiceManagerProcess"
      options = ${pipeline}  # References the top-level pipeline configuration
    }

    # H2 Database Web Console - separate web interface for database access
    # Runs on its own port (default: 8082) independent of the main HTTP server
    # Security: Restricted to localhost by default
    h2-console {
      className = "org.evochora.node.processes.h2.H2ConsoleProcess"
      options {
        # Enable/disable the console (recommended: disable in production)
        enabled = true

        # Network configuration
        network {
          host = "localhost"  # Restrict to localhost for security
          port = 8082         # Standard H2 console port
        }

        # Database configuration reference (for displaying connection info in logs)
        # References the index-database config to show correct JDBC URL and credentials
        database = ${pipeline.resources.index-database.options}

        # Security: Allow connections from other computers (NOT recommended!)
        allowOthers = false

        # Enable SSL/TLS (requires SSL certificate configuration)
        useSSL = false

        # Enable H2 trace output for debugging
        trace = false
      }
    }

    # H2 TCP Server - allows external database clients (IntelliJ, DBeaver, etc.) to connect
    # This is an alternative to AUTO_SERVER=TRUE (which is incompatible with DB_CLOSE_ON_EXIT=FALSE)
    # Security: Restricted to localhost by default
    h2-tcp-server {
      className = "org.evochora.node.processes.h2.H2TcpServerProcess"
      options {
        # Enable/disable the TCP server (default: false = disabled, opt-in)
        # Set to true to allow external database client connections
        enabled = true

        # TCP port for database connections (default: 9092)
        tcpPort = 9092

        # Database configuration reference (for displaying correct JDBC URL in logs)
        # References the index-database config to build the TCP connection URL
        database = ${pipeline.resources.index-database.options}

        # Security: Allow connections from other computers (NOT recommended!)
        # false = localhost only (default, secure)
        # true = allow remote connections (security risk!)
        tcpAllowOthers = false
      }
    }

    # Logical name for the HTTP server process
    http {
      className = "org.evochora.node.processes.http.HttpServerProcess"

      # Declare dependency on pipeline process
      require = {
        serviceManager = "pipeline"
      }

      options {
        network {
          host = "localhost"
          port = 8080

          # Optional: Configure the Jetty thread pool for HTTP request handling
          # Threads are named "<processName>-http-<number>" for easier monitoring
          threadPool {
            minThreads = 8         # Minimum number of threads (default: 8)
            maxThreads = 200       # Maximum number of threads (default: 200)
            idleTimeoutMs = 60000  # Idle timeout in milliseconds (default: 60000)
          }
        }

        # All routes are defined within the HttpServerProcess's options
        routes {
          # The nesting of objects defines the URL paths.
          # Actions ($controller, $static) are defined by keys prefixed with '$'.
          pipeline {
            # ACTION: Serves static UI files at the base path "/pipeline"
            # The static file handler serves from the classpath. A directory named
            # 'web/pipeline-control' should exist in 'src/main/resources'.
            #"$static" = "/web/pipeline-control"

            # Builds the sub-path "/pipeline/api"
            api {
              # ACTION: Serves a controller at "/pipeline/api"
              "$controller" {
                className = "org.evochora.node.processes.http.api.pipeline.PipelineController"
                options {}
              }
            }
          }
        }
      }
    }
  }
}

logging {
  format = "PLAIN"  # Can be "PLAIN" or "JSON". Defaults to JSON
  default-level = "INFO"  # Default log level for all loggers
  levels {
    # Specific logger levels - override the default for particular components
    "org.evochora.datapipeline.ServiceManager" = "INFO"
    #"org.evochora.datapipeline.services.indexers.DummyIndexer" = "DEBUG"
  }
}